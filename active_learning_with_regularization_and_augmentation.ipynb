{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26f93bb3",
   "metadata": {},
   "source": [
    "## Active Learning with Regularization and Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d581cf9",
   "metadata": {},
   "source": [
    "After performing some unsupervised analysis, it's clear that there are a few classes that are hard to distinguish in the feature space. To help identify a strong separation boundary between these more fuzzy observations, we can apply two techniques:\n",
    "\n",
    "1. Active Learning to query for examples which the model has a hard time discerning. \n",
    "2. Data Augmentation to create new samples from the points that the model has a hard time discerning. \n",
    "\n",
    "With active learning, we hope to be more thoughtful about which labels we choose to extract from the database since retrieving labels can be an expensive task. Moreover, with data augmentation, we hope to make our model more robust in classifying fuzzier data points without having to query the database for additional labels. Though augmented samples increase our model's training time (which likely has its own costs), they don't require us to pay any costs associated with generating labels. We are willing to make this tradeoff."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac79161f",
   "metadata": {},
   "source": [
    "To leverage these methods in our approach, we build the following modeling pipeline:\n",
    "\n",
    "1. Generate initial random sample of data and train on our CNN. We choose to collect an equal number of instances per class so the model can identify which classes are separable and which aren't. The remaining examples go into a sampling pool which our CNN can query.\n",
    "2. Create new samples with data generator based on the initial random sample.\n",
    "3. Train CNN on this initial sample and its generated examples.\n",
    "4. Query for observations that model has most uncertainty in assigning a label.\n",
    "5. Generate new data samples from queried data.\n",
    "6. Train CNN on queried and new data samples. Remove the queried samples from the sampling pool.\n",
    "7. Repeat steps 4-6.\n",
    "\n",
    "We hope that our setup will allow us to build a classifier that hits our accuracy benchmark using as few labels as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5eda981b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import (\n",
    "    Input, Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Concatenate\n",
    ")\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.experimental.preprocessing import (\n",
    "    RandomRotation, RandomFlip, RandomTranslation, RandomZoom\n",
    ")\n",
    "from modAL.models import ActiveLearner\n",
    "from modAL.uncertainty import entropy_sampling, uncertainty_sampling, margin_sampling\n",
    "from data.get_data import load_mnist\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c1576da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here y_train serves as our mock database to collect labels\n",
    "X_train, y_train = load_mnist('data/f_mnist_data', kind='train')\n",
    "X_test, y_test = load_mnist('data/f_mnist_data', kind='t10k')\n",
    "\n",
    "# minmax scaling\n",
    "X_train, X_test = X_train/255.0, X_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1b512e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(60000, 28, 28, 1)\n",
    "X_test = X_test.reshape(10000, 28, 28, 1)\n",
    "\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "# assemble initial data sample for active learner\n",
    "initial_idx = np.array([],dtype=int)\n",
    "n_instances_per_class = 200\n",
    "for i in range(10):\n",
    "    idx = np.random.choice(np.where(y_train[:,i]==1)[0], size=n_instances_per_class, replace=False)\n",
    "    initial_idx = np.concatenate((initial_idx, idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63da9cd",
   "metadata": {},
   "source": [
    "The next cell implements a simple data generator to create new training examples. To synthesize new examples, we apply some fairly standard image transformations to our input.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "abe722c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-27 12:22:08.786869: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Concatenate\n",
    "\n",
    "augmenter = Sequential([\n",
    "    RandomFlip(\"horizontal_and_vertical\"),\n",
    "    RandomRotation(0.15),\n",
    "    RandomTranslation(height_factor=(-.15, .15), width_factor=(-.15, .15)),\n",
    "    RandomZoom(height_factor=(-.15, .15))\n",
    "])\n",
    "\n",
    "def generate_new_samples(X, y, augmenter=augmenter, num_samples=1):\n",
    "    if num_samples > 1:\n",
    "        sample_batch = Concatenate(axis=0)([augmenter(X) for _ in range(num_samples)])\n",
    "        sample_labels = Concatenate(axis=0)([y for _ in range(num_samples)])\n",
    "        return sample_batch.numpy(), sample_labels.numpy()\n",
    "    else:\n",
    "        sample_batch = augmenter(X).numpy()\n",
    "        # sample_label is same as y\n",
    "        return sample_batch, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8b6c3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forming the initial training data\n",
    "X_initial = X_train[initial_idx]\n",
    "y_initial = y_train[initial_idx]\n",
    "\n",
    "# generate augmented samples\n",
    "X_gen, y_gen = generate_new_samples(X_initial, y_initial, num_samples=1)\n",
    "\n",
    "# generate the sampling pool\n",
    "# remove the initial data from the training dataset\n",
    "X_pool = np.delete(X_train, initial_idx, axis=0)\n",
    "y_pool = np.delete(y_train, initial_idx, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c18e7b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_keras_model():\n",
    "\n",
    "    # model configs and hyperparams\n",
    "    dim = (28,28,1)\n",
    "    dropout_rate = .25\n",
    "    \n",
    "    model = Sequential([\n",
    "        Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same', \n",
    "               input_shape=dim),\n",
    "        BatchNormalization(),\n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(dropout_rate),\n",
    "\n",
    "        Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),     \n",
    "        MaxPooling2D(pool_size=(2, 2)),\n",
    "        Dropout(dropout_rate),\n",
    "        \n",
    "        Conv2D(256, kernel_size=(3, 3), activation='relu', padding='same'),\n",
    "        BatchNormalization(),  \n",
    "        MaxPooling2D(pool_size=(2, 2)),   \n",
    "        Dropout(dropout_rate),\n",
    "        \n",
    "        Flatten(),\n",
    "        \n",
    "        Dense(1024, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        \n",
    "        Dense(512, activation='relu'),\n",
    "        Dropout(dropout_rate),\n",
    "        \n",
    "        Dense(10, activation='softmax')\n",
    "    ])\n",
    "\n",
    "    adam = Adam(lr=0.001, decay=1e-6)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "classifier = KerasClassifier(create_keras_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ff2ff23e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-27 12:22:10.807925: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "125/125 [==============================] - 9s 70ms/step - loss: 2.4874 - accuracy: 0.3578\n",
      "Epoch 2/40\n",
      "125/125 [==============================] - 9s 70ms/step - loss: 1.2106 - accuracy: 0.5539\n",
      "Epoch 3/40\n",
      "125/125 [==============================] - 9s 69ms/step - loss: 1.0343 - accuracy: 0.6157\n",
      "Epoch 4/40\n",
      "125/125 [==============================] - 9s 70ms/step - loss: 0.9364 - accuracy: 0.6494\n",
      "Epoch 5/40\n",
      "125/125 [==============================] - 9s 71ms/step - loss: 0.8174 - accuracy: 0.6839\n",
      "Epoch 6/40\n",
      "125/125 [==============================] - 10s 79ms/step - loss: 0.7474 - accuracy: 0.7398\n",
      "Epoch 7/40\n",
      "125/125 [==============================] - 9s 68ms/step - loss: 0.7046 - accuracy: 0.7524\n",
      "Epoch 8/40\n",
      "125/125 [==============================] - 8s 68ms/step - loss: 0.6382 - accuracy: 0.7731\n",
      "Epoch 9/40\n",
      "125/125 [==============================] - 9s 69ms/step - loss: 0.6009 - accuracy: 0.7728\n",
      "Epoch 10/40\n",
      "125/125 [==============================] - 9s 70ms/step - loss: 0.5417 - accuracy: 0.8098\n",
      "Epoch 11/40\n",
      "125/125 [==============================] - 9s 70ms/step - loss: 0.5345 - accuracy: 0.8070\n",
      "Epoch 12/40\n",
      "125/125 [==============================] - 9s 71ms/step - loss: 0.4620 - accuracy: 0.8290\n",
      "Epoch 13/40\n",
      "125/125 [==============================] - 9s 70ms/step - loss: 0.4352 - accuracy: 0.8388\n",
      "Epoch 14/40\n",
      "125/125 [==============================] - 9s 69ms/step - loss: 0.4316 - accuracy: 0.8434\n",
      "Epoch 15/40\n",
      "125/125 [==============================] - 9s 70ms/step - loss: 0.4197 - accuracy: 0.8505\n",
      "Epoch 16/40\n",
      "125/125 [==============================] - 9s 71ms/step - loss: 0.3466 - accuracy: 0.8705\n",
      "Epoch 17/40\n",
      "125/125 [==============================] - 9s 70ms/step - loss: 0.3098 - accuracy: 0.8841\n",
      "Epoch 18/40\n",
      "125/125 [==============================] - 9s 69ms/step - loss: 0.3082 - accuracy: 0.8926\n",
      "Epoch 19/40\n",
      "125/125 [==============================] - 9s 69ms/step - loss: 0.3091 - accuracy: 0.8863\n",
      "Epoch 20/40\n",
      "125/125 [==============================] - 9s 68ms/step - loss: 0.2445 - accuracy: 0.9117\n",
      "Epoch 21/40\n",
      "125/125 [==============================] - 8s 68ms/step - loss: 0.2580 - accuracy: 0.9074\n",
      "Epoch 22/40\n",
      "125/125 [==============================] - 8s 67ms/step - loss: 0.2318 - accuracy: 0.9175\n",
      "Epoch 23/40\n",
      "125/125 [==============================] - 9s 69ms/step - loss: 0.2288 - accuracy: 0.9167\n",
      "Epoch 24/40\n",
      "125/125 [==============================] - 9s 68ms/step - loss: 0.2046 - accuracy: 0.9239\n",
      "Epoch 25/40\n",
      "125/125 [==============================] - 9s 68ms/step - loss: 0.2487 - accuracy: 0.9208\n",
      "Epoch 26/40\n",
      "125/125 [==============================] - 9s 68ms/step - loss: 0.2198 - accuracy: 0.9266\n",
      "Epoch 27/40\n",
      "125/125 [==============================] - 9s 69ms/step - loss: 0.1822 - accuracy: 0.9411\n",
      "Epoch 28/40\n",
      "125/125 [==============================] - 9s 69ms/step - loss: 0.1963 - accuracy: 0.9386\n",
      "Epoch 29/40\n",
      "125/125 [==============================] - 9s 69ms/step - loss: 0.1670 - accuracy: 0.9438\n",
      "Epoch 30/40\n",
      "125/125 [==============================] - 9s 69ms/step - loss: 0.2010 - accuracy: 0.9369\n",
      "Epoch 31/40\n",
      "125/125 [==============================] - 9s 69ms/step - loss: 0.1454 - accuracy: 0.9531\n",
      "Epoch 32/40\n",
      "125/125 [==============================] - 9s 70ms/step - loss: 0.1558 - accuracy: 0.9491\n",
      "Epoch 33/40\n",
      "125/125 [==============================] - 9s 69ms/step - loss: 0.1584 - accuracy: 0.9463\n",
      "Epoch 34/40\n",
      "125/125 [==============================] - 9s 69ms/step - loss: 0.1680 - accuracy: 0.9478\n",
      "Epoch 35/40\n",
      "125/125 [==============================] - 9s 69ms/step - loss: 0.1540 - accuracy: 0.9459\n",
      "Epoch 36/40\n",
      "125/125 [==============================] - 9s 70ms/step - loss: 0.1281 - accuracy: 0.9516\n",
      "Epoch 37/40\n",
      "125/125 [==============================] - 9s 72ms/step - loss: 0.1425 - accuracy: 0.9524\n",
      "Epoch 38/40\n",
      "125/125 [==============================] - 9s 71ms/step - loss: 0.1380 - accuracy: 0.9568\n",
      "Epoch 39/40\n",
      "125/125 [==============================] - 9s 71ms/step - loss: 0.1565 - accuracy: 0.9540\n",
      "Epoch 40/40\n",
      "125/125 [==============================] - 9s 70ms/step - loss: 0.1076 - accuracy: 0.9662\n",
      "313/313 [==============================] - 7s 20ms/step - loss: 0.9949 - accuracy: 0.8494\n",
      "baseline score: 0.849399983882904\n"
     ]
    }
   ],
   "source": [
    "# training params\n",
    "epochs = 40\n",
    "\n",
    "# initialize ActiveLearner\n",
    "learner = ActiveLearner(\n",
    "    estimator=classifier,\n",
    "    X_training=np.concatenate([X_initial, X_gen], axis=0), \n",
    "    y_training=np.concatenate([y_initial, y_gen], axis=0),\n",
    "    query_strategy=margin_sampling,\n",
    "    verbose=1,\n",
    "    epochs=epochs,\n",
    ")\n",
    "\n",
    "# baseline score\n",
    "print(f\"baseline score: {learner.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f036154",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query no. 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imuzumdar/opt/miniconda3/envs/fashion_mnist/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "150/150 [==============================] - 11s 69ms/step - loss: 2.5417 - accuracy: 0.3330\n",
      "Epoch 2/40\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 1.2814 - accuracy: 0.5189\n",
      "Epoch 3/40\n",
      "150/150 [==============================] - 11s 70ms/step - loss: 1.1470 - accuracy: 0.5729\n",
      "Epoch 4/40\n",
      "150/150 [==============================] - 11s 71ms/step - loss: 1.0186 - accuracy: 0.6115\n",
      "Epoch 5/40\n",
      "150/150 [==============================] - 11s 72ms/step - loss: 0.9505 - accuracy: 0.6383\n",
      "Epoch 6/40\n",
      "150/150 [==============================] - 11s 72ms/step - loss: 0.8582 - accuracy: 0.6782\n",
      "Epoch 7/40\n",
      "150/150 [==============================] - 11s 72ms/step - loss: 0.8288 - accuracy: 0.6700\n",
      "Epoch 8/40\n",
      "150/150 [==============================] - 11s 71ms/step - loss: 0.7677 - accuracy: 0.6992\n",
      "Epoch 9/40\n",
      "150/150 [==============================] - 11s 72ms/step - loss: 0.7402 - accuracy: 0.7096\n",
      "Epoch 10/40\n",
      "150/150 [==============================] - 11s 72ms/step - loss: 0.6885 - accuracy: 0.7295\n",
      "Epoch 11/40\n",
      "150/150 [==============================] - 11s 71ms/step - loss: 0.6237 - accuracy: 0.7641\n",
      "Epoch 12/40\n",
      "150/150 [==============================] - 11s 71ms/step - loss: 0.6040 - accuracy: 0.7564\n",
      "Epoch 13/40\n",
      "150/150 [==============================] - 11s 72ms/step - loss: 0.5390 - accuracy: 0.7909\n",
      "Epoch 14/40\n",
      "150/150 [==============================] - 11s 72ms/step - loss: 0.5378 - accuracy: 0.7969\n",
      "Epoch 15/40\n",
      "150/150 [==============================] - 11s 75ms/step - loss: 0.5201 - accuracy: 0.7960\n",
      "Epoch 16/40\n",
      "150/150 [==============================] - 11s 73ms/step - loss: 0.4402 - accuracy: 0.8302\n",
      "Epoch 17/40\n",
      "150/150 [==============================] - 11s 72ms/step - loss: 0.4499 - accuracy: 0.8231\n",
      "Epoch 18/40\n",
      "150/150 [==============================] - 11s 72ms/step - loss: 0.4141 - accuracy: 0.8454\n",
      "Epoch 19/40\n",
      "150/150 [==============================] - 11s 71ms/step - loss: 0.4174 - accuracy: 0.8401\n",
      "Epoch 20/40\n",
      "150/150 [==============================] - 11s 72ms/step - loss: 0.3618 - accuracy: 0.8605\n",
      "Epoch 21/40\n",
      "150/150 [==============================] - 11s 73ms/step - loss: 0.3353 - accuracy: 0.8711\n",
      "Epoch 22/40\n",
      "150/150 [==============================] - 11s 75ms/step - loss: 0.3430 - accuracy: 0.8721\n",
      "Epoch 23/40\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.3110 - accuracy: 0.8902\n",
      "Epoch 24/40\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.2944 - accuracy: 0.8985\n",
      "Epoch 25/40\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.3219 - accuracy: 0.8868\n",
      "Epoch 26/40\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.2862 - accuracy: 0.8946\n",
      "Epoch 27/40\n",
      "150/150 [==============================] - 11s 72ms/step - loss: 0.2328 - accuracy: 0.9084\n",
      "Epoch 28/40\n",
      "150/150 [==============================] - 11s 71ms/step - loss: 0.2411 - accuracy: 0.9197\n",
      "Epoch 29/40\n",
      "150/150 [==============================] - 11s 72ms/step - loss: 0.2419 - accuracy: 0.9096\n",
      "Epoch 30/40\n",
      "150/150 [==============================] - 11s 73ms/step - loss: 0.2053 - accuracy: 0.9292\n",
      "Epoch 31/40\n",
      "150/150 [==============================] - 11s 72ms/step - loss: 0.2565 - accuracy: 0.9124\n",
      "Epoch 32/40\n",
      "150/150 [==============================] - 11s 72ms/step - loss: 0.1930 - accuracy: 0.9351\n",
      "Epoch 33/40\n",
      "150/150 [==============================] - 10s 70ms/step - loss: 0.1886 - accuracy: 0.9332\n",
      "Epoch 34/40\n",
      "150/150 [==============================] - 11s 72ms/step - loss: 0.1829 - accuracy: 0.9347\n",
      "Epoch 35/40\n",
      "150/150 [==============================] - 11s 71ms/step - loss: 0.1889 - accuracy: 0.9329\n",
      "Epoch 36/40\n",
      "150/150 [==============================] - 10s 69ms/step - loss: 0.2070 - accuracy: 0.9295\n",
      "Epoch 37/40\n",
      "150/150 [==============================] - 10s 70ms/step - loss: 0.1634 - accuracy: 0.9431\n",
      "Epoch 38/40\n",
      "150/150 [==============================] - 11s 73ms/step - loss: 0.1838 - accuracy: 0.9411\n",
      "Epoch 39/40\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.1587 - accuracy: 0.9438\n",
      "Epoch 40/40\n",
      "150/150 [==============================] - 11s 74ms/step - loss: 0.1410 - accuracy: 0.9521\n",
      "model accuracy: 0.8604999780654907\n",
      "Query no. 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imuzumdar/opt/miniconda3/envs/fashion_mnist/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "175/175 [==============================] - 13s 69ms/step - loss: 2.6430 - accuracy: 0.3243\n",
      "Epoch 2/40\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 1.3427 - accuracy: 0.4841\n",
      "Epoch 3/40\n",
      "175/175 [==============================] - 13s 71ms/step - loss: 1.1777 - accuracy: 0.5481\n",
      "Epoch 4/40\n",
      "175/175 [==============================] - 13s 72ms/step - loss: 1.0816 - accuracy: 0.5749\n",
      "Epoch 5/40\n",
      "175/175 [==============================] - 13s 73ms/step - loss: 1.0243 - accuracy: 0.6118\n",
      "Epoch 6/40\n",
      "175/175 [==============================] - 13s 73ms/step - loss: 0.9559 - accuracy: 0.6276\n",
      "Epoch 7/40\n",
      "175/175 [==============================] - 12s 71ms/step - loss: 0.9066 - accuracy: 0.6465\n",
      "Epoch 8/40\n",
      "175/175 [==============================] - 12s 70ms/step - loss: 0.8486 - accuracy: 0.6661\n",
      "Epoch 9/40\n",
      "175/175 [==============================] - 13s 76ms/step - loss: 0.7862 - accuracy: 0.6887\n",
      "Epoch 10/40\n",
      "175/175 [==============================] - 13s 76ms/step - loss: 0.7624 - accuracy: 0.7073\n",
      "Epoch 11/40\n",
      "175/175 [==============================] - 13s 76ms/step - loss: 0.7337 - accuracy: 0.7191\n",
      "Epoch 12/40\n",
      "175/175 [==============================] - 13s 73ms/step - loss: 0.6817 - accuracy: 0.7285\n",
      "Epoch 13/40\n",
      "175/175 [==============================] - 12s 71ms/step - loss: 0.5965 - accuracy: 0.7658\n",
      "Epoch 14/40\n",
      "175/175 [==============================] - 13s 74ms/step - loss: 0.5913 - accuracy: 0.7709\n",
      "Epoch 15/40\n",
      "175/175 [==============================] - 13s 73ms/step - loss: 0.5828 - accuracy: 0.7718\n",
      "Epoch 16/40\n",
      "175/175 [==============================] - 14s 77ms/step - loss: 0.5216 - accuracy: 0.7988\n",
      "Epoch 17/40\n",
      "175/175 [==============================] - 13s 74ms/step - loss: 0.4870 - accuracy: 0.8209\n",
      "Epoch 18/40\n",
      "175/175 [==============================] - 13s 73ms/step - loss: 0.4715 - accuracy: 0.8191\n",
      "Epoch 19/40\n",
      "175/175 [==============================] - 13s 75ms/step - loss: 0.4487 - accuracy: 0.8341\n",
      "Epoch 20/40\n",
      "175/175 [==============================] - 13s 75ms/step - loss: 0.4475 - accuracy: 0.8239\n",
      "Epoch 21/40\n",
      "175/175 [==============================] - 13s 73ms/step - loss: 0.3729 - accuracy: 0.8642\n",
      "Epoch 22/40\n",
      "175/175 [==============================] - 13s 72ms/step - loss: 0.3580 - accuracy: 0.8661\n",
      "Epoch 23/40\n",
      "175/175 [==============================] - 13s 74ms/step - loss: 0.3896 - accuracy: 0.8622\n",
      "Epoch 24/40\n",
      "175/175 [==============================] - 13s 74ms/step - loss: 0.3539 - accuracy: 0.8701\n",
      "Epoch 25/40\n",
      "175/175 [==============================] - 13s 73ms/step - loss: 0.3153 - accuracy: 0.8856\n",
      "Epoch 26/40\n",
      "175/175 [==============================] - 13s 73ms/step - loss: 0.3151 - accuracy: 0.8920\n",
      "Epoch 27/40\n",
      "175/175 [==============================] - 13s 74ms/step - loss: 0.2740 - accuracy: 0.8993\n",
      "Epoch 28/40\n",
      "175/175 [==============================] - 13s 74ms/step - loss: 0.2634 - accuracy: 0.9061\n",
      "Epoch 29/40\n",
      "175/175 [==============================] - 13s 74ms/step - loss: 0.2604 - accuracy: 0.9053\n",
      "Epoch 30/40\n",
      "175/175 [==============================] - 13s 74ms/step - loss: 0.2444 - accuracy: 0.9071\n",
      "Epoch 31/40\n",
      "175/175 [==============================] - 12s 71ms/step - loss: 0.2337 - accuracy: 0.9136\n",
      "Epoch 32/40\n",
      "175/175 [==============================] - 12s 71ms/step - loss: 0.2159 - accuracy: 0.9207\n",
      "Epoch 33/40\n",
      "175/175 [==============================] - 13s 74ms/step - loss: 0.2315 - accuracy: 0.9187\n",
      "Epoch 34/40\n",
      "175/175 [==============================] - 13s 73ms/step - loss: 0.2063 - accuracy: 0.9275\n",
      "Epoch 35/40\n",
      "175/175 [==============================] - 13s 73ms/step - loss: 0.2291 - accuracy: 0.9161\n",
      "Epoch 36/40\n",
      "175/175 [==============================] - 13s 73ms/step - loss: 0.1833 - accuracy: 0.9332\n",
      "Epoch 37/40\n",
      "175/175 [==============================] - 13s 75ms/step - loss: 0.1945 - accuracy: 0.9380\n",
      "Epoch 38/40\n",
      "175/175 [==============================] - 13s 74ms/step - loss: 0.2050 - accuracy: 0.9253\n",
      "Epoch 39/40\n",
      "175/175 [==============================] - 14s 79ms/step - loss: 0.2003 - accuracy: 0.9336\n",
      "Epoch 40/40\n",
      "175/175 [==============================] - 13s 75ms/step - loss: 0.1900 - accuracy: 0.9385\n",
      "model accuracy: 0.8623999953269958\n",
      "Query no. 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imuzumdar/opt/miniconda3/envs/fashion_mnist/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 2.4219 - accuracy: 0.3153\n",
      "Epoch 2/40\n",
      "200/200 [==============================] - 14s 69ms/step - loss: 1.3256 - accuracy: 0.4869\n",
      "Epoch 3/40\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 1.2058 - accuracy: 0.5270\n",
      "Epoch 4/40\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 1.1017 - accuracy: 0.5692\n",
      "Epoch 5/40\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 1.0445 - accuracy: 0.5882\n",
      "Epoch 6/40\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.9840 - accuracy: 0.6121\n",
      "Epoch 7/40\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.9215 - accuracy: 0.6330\n",
      "Epoch 8/40\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.8767 - accuracy: 0.6468\n",
      "Epoch 9/40\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.8324 - accuracy: 0.6702\n",
      "Epoch 10/40\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.7837 - accuracy: 0.6748\n",
      "Epoch 11/40\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.7653 - accuracy: 0.7006\n",
      "Epoch 12/40\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.6980 - accuracy: 0.7217\n",
      "Epoch 13/40\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.6856 - accuracy: 0.7269\n",
      "Epoch 14/40\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.6439 - accuracy: 0.7515\n",
      "Epoch 15/40\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.6069 - accuracy: 0.7610\n",
      "Epoch 16/40\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.5761 - accuracy: 0.7723\n",
      "Epoch 17/40\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.5475 - accuracy: 0.7968\n",
      "Epoch 18/40\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.5295 - accuracy: 0.7994\n",
      "Epoch 19/40\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.5189 - accuracy: 0.8076\n",
      "Epoch 20/40\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.4546 - accuracy: 0.8332\n",
      "Epoch 21/40\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.4509 - accuracy: 0.8300\n",
      "Epoch 22/40\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.4275 - accuracy: 0.8386\n",
      "Epoch 23/40\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3992 - accuracy: 0.8583\n",
      "Epoch 24/40\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.3870 - accuracy: 0.8612\n",
      "Epoch 25/40\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.3255 - accuracy: 0.8802\n",
      "Epoch 26/40\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.3039 - accuracy: 0.8931\n",
      "Epoch 27/40\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.2973 - accuracy: 0.8924\n",
      "Epoch 28/40\n",
      "200/200 [==============================] - 15s 76ms/step - loss: 0.3201 - accuracy: 0.8895\n",
      "Epoch 29/40\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.2646 - accuracy: 0.9036\n",
      "Epoch 30/40\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.2748 - accuracy: 0.9005\n",
      "Epoch 31/40\n",
      "200/200 [==============================] - 15s 77ms/step - loss: 0.2857 - accuracy: 0.8986\n",
      "Epoch 32/40\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.2679 - accuracy: 0.9036\n",
      "Epoch 33/40\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.2569 - accuracy: 0.9103\n",
      "Epoch 34/40\n",
      "200/200 [==============================] - 14s 72ms/step - loss: 0.2546 - accuracy: 0.9125\n",
      "Epoch 35/40\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 0.2030 - accuracy: 0.9254\n",
      "Epoch 36/40\n",
      "200/200 [==============================] - 15s 73ms/step - loss: 0.2011 - accuracy: 0.9284\n",
      "Epoch 37/40\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.2451 - accuracy: 0.9170\n",
      "Epoch 38/40\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 0.2409 - accuracy: 0.9174\n",
      "Epoch 39/40\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.2132 - accuracy: 0.9232\n",
      "Epoch 40/40\n",
      "200/200 [==============================] - 14s 70ms/step - loss: 0.1969 - accuracy: 0.9320\n",
      "model accuracy: 0.8683000206947327\n",
      "Query no. 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imuzumdar/opt/miniconda3/envs/fashion_mnist/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "225/225 [==============================] - 15s 66ms/step - loss: 2.3939 - accuracy: 0.3073\n",
      "Epoch 2/40\n",
      "225/225 [==============================] - 15s 66ms/step - loss: 1.3686 - accuracy: 0.4589\n",
      "Epoch 3/40\n",
      "225/225 [==============================] - 15s 65ms/step - loss: 1.2439 - accuracy: 0.5055\n",
      "Epoch 4/40\n",
      "225/225 [==============================] - 15s 66ms/step - loss: 1.1691 - accuracy: 0.5434\n",
      "Epoch 5/40\n",
      "225/225 [==============================] - 15s 66ms/step - loss: 1.0597 - accuracy: 0.5686\n",
      "Epoch 6/40\n",
      "225/225 [==============================] - 15s 66ms/step - loss: 1.0008 - accuracy: 0.5970\n",
      "Epoch 7/40\n",
      "225/225 [==============================] - 15s 65ms/step - loss: 0.9551 - accuracy: 0.6147\n",
      "Epoch 8/40\n",
      "225/225 [==============================] - 15s 67ms/step - loss: 0.9270 - accuracy: 0.6268\n",
      "Epoch 9/40\n",
      "225/225 [==============================] - 121s 539ms/step - loss: 0.8866 - accuracy: 0.6322\n",
      "Epoch 10/40\n",
      "225/225 [==============================] - 45s 202ms/step - loss: 0.8345 - accuracy: 0.6691\n",
      "Epoch 11/40\n",
      "225/225 [==============================] - 83s 371ms/step - loss: 0.7933 - accuracy: 0.6764\n",
      "Epoch 12/40\n",
      "225/225 [==============================] - 16s 70ms/step - loss: 0.7442 - accuracy: 0.7023\n",
      "Epoch 13/40\n",
      "225/225 [==============================] - 16s 71ms/step - loss: 0.7553 - accuracy: 0.6974\n",
      "Epoch 14/40\n",
      "225/225 [==============================] - 17s 74ms/step - loss: 0.6751 - accuracy: 0.7263\n",
      "Epoch 15/40\n",
      "225/225 [==============================] - 16s 70ms/step - loss: 0.6372 - accuracy: 0.7431\n",
      "Epoch 16/40\n",
      "225/225 [==============================] - 16s 71ms/step - loss: 0.6133 - accuracy: 0.7534\n",
      "Epoch 17/40\n",
      "225/225 [==============================] - 16s 71ms/step - loss: 0.6069 - accuracy: 0.7620\n",
      "Epoch 18/40\n",
      "225/225 [==============================] - 16s 70ms/step - loss: 0.5749 - accuracy: 0.7668\n",
      "Epoch 19/40\n",
      "225/225 [==============================] - 16s 70ms/step - loss: 0.5301 - accuracy: 0.7935\n",
      "Epoch 20/40\n",
      "225/225 [==============================] - 16s 71ms/step - loss: 0.5408 - accuracy: 0.7883\n",
      "Epoch 21/40\n",
      "225/225 [==============================] - 16s 70ms/step - loss: 0.4611 - accuracy: 0.8196\n",
      "Epoch 22/40\n",
      "225/225 [==============================] - 16s 70ms/step - loss: 0.4511 - accuracy: 0.8302\n",
      "Epoch 23/40\n",
      "225/225 [==============================] - 15s 68ms/step - loss: 0.4307 - accuracy: 0.8428\n",
      "Epoch 24/40\n",
      "225/225 [==============================] - 459s 2s/step - loss: 0.4172 - accuracy: 0.8413\n",
      "Epoch 25/40\n",
      "225/225 [==============================] - 34s 153ms/step - loss: 0.3752 - accuracy: 0.8576\n",
      "Epoch 26/40\n",
      "225/225 [==============================] - 759s 3s/step - loss: 0.3612 - accuracy: 0.8691\n",
      "Epoch 27/40\n",
      "225/225 [==============================] - 2285s 10s/step - loss: 0.3262 - accuracy: 0.8854\n",
      "Epoch 28/40\n",
      "225/225 [==============================] - 4921s 22s/step - loss: 0.3559 - accuracy: 0.8657\n",
      "Epoch 29/40\n",
      "225/225 [==============================] - 92s 411ms/step - loss: 0.3223 - accuracy: 0.8806\n",
      "Epoch 30/40\n",
      "225/225 [==============================] - 138s 615ms/step - loss: 0.2831 - accuracy: 0.8970\n",
      "Epoch 31/40\n",
      "225/225 [==============================] - 2583s 12s/step - loss: 0.3092 - accuracy: 0.8880\n",
      "Epoch 32/40\n",
      "225/225 [==============================] - 50s 223ms/step - loss: 0.2752 - accuracy: 0.8971\n",
      "Epoch 33/40\n",
      "225/225 [==============================] - 24s 108ms/step - loss: 0.2911 - accuracy: 0.8996\n",
      "Epoch 34/40\n",
      "225/225 [==============================] - 64s 283ms/step - loss: 0.2744 - accuracy: 0.9057\n",
      "Epoch 35/40\n",
      "225/225 [==============================] - 97s 433ms/step - loss: 0.2462 - accuracy: 0.9100\n",
      "Epoch 36/40\n",
      "225/225 [==============================] - 99s 442ms/step - loss: 0.2512 - accuracy: 0.9169\n",
      "Epoch 37/40\n",
      "225/225 [==============================] - 39s 175ms/step - loss: 0.2261 - accuracy: 0.9185\n",
      "Epoch 38/40\n",
      "225/225 [==============================] - 16s 69ms/step - loss: 0.2234 - accuracy: 0.9213\n",
      "Epoch 39/40\n",
      "225/225 [==============================] - 15s 66ms/step - loss: 0.2294 - accuracy: 0.9195\n",
      "Epoch 40/40\n",
      "225/225 [==============================] - 15s 67ms/step - loss: 0.2373 - accuracy: 0.9210\n",
      "model accuracy: 0.8737999796867371\n",
      "Query no. 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imuzumdar/opt/miniconda3/envs/fashion_mnist/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "250/250 [==============================] - 35s 137ms/step - loss: 2.4411 - accuracy: 0.3212\n",
      "Epoch 2/40\n",
      "250/250 [==============================] - 47s 189ms/step - loss: 1.3732 - accuracy: 0.4534\n",
      "Epoch 3/40\n",
      "250/250 [==============================] - 93s 375ms/step - loss: 1.2085 - accuracy: 0.5145\n",
      "Epoch 4/40\n",
      "250/250 [==============================] - 25s 101ms/step - loss: 1.1675 - accuracy: 0.5281\n",
      "Epoch 5/40\n",
      "250/250 [==============================] - 43s 171ms/step - loss: 1.0515 - accuracy: 0.5797\n",
      "Epoch 6/40\n",
      "250/250 [==============================] - 466s 2s/step - loss: 1.0183 - accuracy: 0.5919\n",
      "Epoch 7/40\n",
      "250/250 [==============================] - 531s 2s/step - loss: 0.9854 - accuracy: 0.5994\n",
      "Epoch 8/40\n",
      "250/250 [==============================] - 241s 969ms/step - loss: 0.9220 - accuracy: 0.6315\n",
      "Epoch 9/40\n",
      "250/250 [==============================] - 17s 70ms/step - loss: 0.8767 - accuracy: 0.6505\n",
      "Epoch 10/40\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.8639 - accuracy: 0.6471\n",
      "Epoch 11/40\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.7947 - accuracy: 0.6775\n",
      "Epoch 12/40\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.7514 - accuracy: 0.6930\n",
      "Epoch 13/40\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.7211 - accuracy: 0.7084\n",
      "Epoch 14/40\n",
      "250/250 [==============================] - 17s 70ms/step - loss: 0.6883 - accuracy: 0.7234\n",
      "Epoch 15/40\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.6681 - accuracy: 0.7302\n",
      "Epoch 16/40\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.6360 - accuracy: 0.7413\n",
      "Epoch 17/40\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.6164 - accuracy: 0.7552\n",
      "Epoch 18/40\n",
      "250/250 [==============================] - 1070s 4s/step - loss: 0.5978 - accuracy: 0.7692\n",
      "Epoch 19/40\n",
      "250/250 [==============================] - 161s 648ms/step - loss: 0.5291 - accuracy: 0.7896\n",
      "Epoch 20/40\n",
      "250/250 [==============================] - 18s 73ms/step - loss: 0.4828 - accuracy: 0.8056\n",
      "Epoch 21/40\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.4986 - accuracy: 0.8046\n",
      "Epoch 22/40\n",
      "250/250 [==============================] - 17s 70ms/step - loss: 0.4982 - accuracy: 0.8135\n",
      "Epoch 23/40\n",
      "250/250 [==============================] - 18s 71ms/step - loss: 0.4564 - accuracy: 0.8294\n",
      "Epoch 24/40\n",
      "250/250 [==============================] - 20s 81ms/step - loss: 0.4451 - accuracy: 0.8295\n",
      "Epoch 25/40\n",
      "250/250 [==============================] - 20s 80ms/step - loss: 0.3908 - accuracy: 0.8564\n",
      "Epoch 26/40\n",
      "250/250 [==============================] - 20s 78ms/step - loss: 0.3734 - accuracy: 0.8663\n",
      "Epoch 27/40\n",
      "250/250 [==============================] - 19s 74ms/step - loss: 0.3706 - accuracy: 0.8601\n",
      "Epoch 28/40\n",
      "250/250 [==============================] - 16s 65ms/step - loss: 0.3405 - accuracy: 0.8720\n",
      "Epoch 29/40\n",
      "250/250 [==============================] - 18s 73ms/step - loss: 0.3752 - accuracy: 0.8674\n",
      "Epoch 30/40\n",
      "250/250 [==============================] - 18s 71ms/step - loss: 0.3138 - accuracy: 0.8829\n",
      "Epoch 31/40\n",
      "250/250 [==============================] - 17s 70ms/step - loss: 0.3233 - accuracy: 0.88640s - loss: 0.3232 - accuracy: 0.88\n",
      "Epoch 32/40\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.3082 - accuracy: 0.8829\n",
      "Epoch 33/40\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.3081 - accuracy: 0.8938\n",
      "Epoch 34/40\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.2971 - accuracy: 0.8912\n",
      "Epoch 35/40\n",
      "250/250 [==============================] - 17s 67ms/step - loss: 0.2537 - accuracy: 0.9120\n",
      "Epoch 36/40\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.2927 - accuracy: 0.9008\n",
      "Epoch 37/40\n",
      "250/250 [==============================] - 17s 68ms/step - loss: 0.2515 - accuracy: 0.9123\n",
      "Epoch 38/40\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.2504 - accuracy: 0.9075\n",
      "Epoch 39/40\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.2434 - accuracy: 0.9140\n",
      "Epoch 40/40\n",
      "250/250 [==============================] - 17s 69ms/step - loss: 0.2556 - accuracy: 0.9151\n",
      "model accuracy: 0.8809000253677368\n"
     ]
    }
   ],
   "source": [
    "n_queries = 5\n",
    "epochs=40\n",
    "accuracy_arr = list()\n",
    "\n",
    "# conduct several rounds of data querying and use the newly queried samples to improve model performance\n",
    "for idx in range(n_queries):\n",
    "    print(f'Query no. {(idx + 1)}')\n",
    "    query_idx, query_instance = learner.query(X_pool, n_instances=400, verbose=0)\n",
    "    \n",
    "    # generate new samples\n",
    "    X_gen, y_gen = generate_new_samples(X_pool[query_idx], y_pool[query_idx], num_samples=1)\n",
    "    \n",
    "    # train active learner on queried data and newly generated samples\n",
    "    learner.teach(\n",
    "        X=np.concatenate([X_pool[query_idx], X_gen], axis=0),\n",
    "        y=np.concatenate([y_pool[query_idx], y_gen], axis=0), \n",
    "        verbose=1,\n",
    "        epochs=epochs,\n",
    "    )\n",
    "    \n",
    "    # remove queried instances from the sampling pool\n",
    "    X_pool = np.delete(X_pool, query_idx, axis=0)\n",
    "    y_pool = np.delete(y_pool, query_idx, axis=0)\n",
    "    \n",
    "    # evaluate performance\n",
    "    model_accuracy = learner.score(X_test, y_test, verbose=0)\n",
    "    accuracy_arr.append(model_accuracy)\n",
    "    print(f\"model accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b6b62da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(learner.X_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bf4e67",
   "metadata": {},
   "source": [
    "So far, we've shown our model 8000 total samples (half of which are synthetic and have zero labeling costs), and our model's accuracy is ~88.1%. We are already close to our baseline results and we've used 60% less labels! \n",
    "\n",
    "Can we improve our model's performance by querying more samples?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9ff3f97",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query no. 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imuzumdar/opt/miniconda3/envs/fashion_mnist/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "275/275 [==============================] - 18s 65ms/step - loss: 2.3780 - accuracy: 0.3158\n",
      "Epoch 2/40\n",
      "275/275 [==============================] - 18s 65ms/step - loss: 1.3652 - accuracy: 0.4513\n",
      "Epoch 3/40\n",
      "275/275 [==============================] - 20s 73ms/step - loss: 1.3034 - accuracy: 0.4780\n",
      "Epoch 4/40\n",
      "275/275 [==============================] - 20s 74ms/step - loss: 1.1778 - accuracy: 0.5192\n",
      "Epoch 5/40\n",
      "275/275 [==============================] - 20s 71ms/step - loss: 1.1317 - accuracy: 0.5401\n",
      "Epoch 6/40\n",
      "275/275 [==============================] - 19s 71ms/step - loss: 1.0520 - accuracy: 0.5712\n",
      "Epoch 7/40\n",
      "275/275 [==============================] - 20s 74ms/step - loss: 0.9956 - accuracy: 0.58780s - loss: 0.9954 - accura\n",
      "Epoch 8/40\n",
      "275/275 [==============================] - 20s 73ms/step - loss: 0.9362 - accuracy: 0.6249\n",
      "Epoch 9/40\n",
      "275/275 [==============================] - 20s 72ms/step - loss: 0.9023 - accuracy: 0.6341\n",
      "Epoch 10/40\n",
      "275/275 [==============================] - 19s 70ms/step - loss: 0.8689 - accuracy: 0.6460\n",
      "Epoch 11/40\n",
      "275/275 [==============================] - 20s 74ms/step - loss: 0.8572 - accuracy: 0.6481\n",
      "Epoch 12/40\n",
      "275/275 [==============================] - 19s 68ms/step - loss: 0.8121 - accuracy: 0.6692\n",
      "Epoch 13/40\n",
      "275/275 [==============================] - 19s 69ms/step - loss: 0.7456 - accuracy: 0.6969\n",
      "Epoch 14/40\n",
      "275/275 [==============================] - 21s 75ms/step - loss: 0.7188 - accuracy: 0.7070\n",
      "Epoch 15/40\n",
      "275/275 [==============================] - 19s 70ms/step - loss: 0.6932 - accuracy: 0.7130\n",
      "Epoch 16/40\n",
      "275/275 [==============================] - 20s 73ms/step - loss: 0.6461 - accuracy: 0.7366\n",
      "Epoch 17/40\n",
      "275/275 [==============================] - 20s 73ms/step - loss: 0.6295 - accuracy: 0.7375\n",
      "Epoch 18/40\n",
      "275/275 [==============================] - 21s 77ms/step - loss: 0.6022 - accuracy: 0.7586\n",
      "Epoch 19/40\n",
      "275/275 [==============================] - 19s 69ms/step - loss: 0.5819 - accuracy: 0.7629\n",
      "Epoch 20/40\n",
      "275/275 [==============================] - 19s 69ms/step - loss: 0.5423 - accuracy: 0.7880\n",
      "Epoch 21/40\n",
      "275/275 [==============================] - 19s 69ms/step - loss: 0.5225 - accuracy: 0.7936\n",
      "Epoch 22/40\n",
      "275/275 [==============================] - 19s 71ms/step - loss: 0.4958 - accuracy: 0.8129\n",
      "Epoch 23/40\n",
      "275/275 [==============================] - 19s 70ms/step - loss: 0.4396 - accuracy: 0.8264\n",
      "Epoch 24/40\n",
      "275/275 [==============================] - 19s 70ms/step - loss: 0.4510 - accuracy: 0.8240\n",
      "Epoch 25/40\n",
      "275/275 [==============================] - 19s 71ms/step - loss: 0.4248 - accuracy: 0.8410\n",
      "Epoch 26/40\n",
      "275/275 [==============================] - 19s 69ms/step - loss: 0.4111 - accuracy: 0.8394\n",
      "Epoch 27/40\n",
      "275/275 [==============================] - 19s 69ms/step - loss: 0.3773 - accuracy: 0.8516\n",
      "Epoch 28/40\n",
      "275/275 [==============================] - 20s 71ms/step - loss: 0.3719 - accuracy: 0.8564\n",
      "Epoch 29/40\n",
      "275/275 [==============================] - 20s 71ms/step - loss: 0.3598 - accuracy: 0.8683\n",
      "Epoch 30/40\n",
      "275/275 [==============================] - 20s 73ms/step - loss: 0.3480 - accuracy: 0.8661\n",
      "Epoch 31/40\n",
      "275/275 [==============================] - 20s 73ms/step - loss: 0.3390 - accuracy: 0.8734\n",
      "Epoch 32/40\n",
      "275/275 [==============================] - 20s 71ms/step - loss: 0.3178 - accuracy: 0.8782\n",
      "Epoch 33/40\n",
      "275/275 [==============================] - 19s 70ms/step - loss: 0.3155 - accuracy: 0.8799\n",
      "Epoch 34/40\n",
      "275/275 [==============================] - 19s 69ms/step - loss: 0.3092 - accuracy: 0.8859\n",
      "Epoch 35/40\n",
      "275/275 [==============================] - 19s 70ms/step - loss: 0.2727 - accuracy: 0.9001\n",
      "Epoch 36/40\n",
      "275/275 [==============================] - 20s 72ms/step - loss: 0.2908 - accuracy: 0.9012\n",
      "Epoch 37/40\n",
      "275/275 [==============================] - 20s 73ms/step - loss: 0.2762 - accuracy: 0.9030\n",
      "Epoch 38/40\n",
      "275/275 [==============================] - 19s 71ms/step - loss: 0.2646 - accuracy: 0.9056\n",
      "Epoch 39/40\n",
      "275/275 [==============================] - 20s 71ms/step - loss: 0.2758 - accuracy: 0.9047\n",
      "Epoch 40/40\n",
      "275/275 [==============================] - 20s 72ms/step - loss: 0.2584 - accuracy: 0.9080\n",
      "model accuracy: 0.8828999996185303\n",
      "Query no. 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imuzumdar/opt/miniconda3/envs/fashion_mnist/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "300/300 [==============================] - 21s 68ms/step - loss: 2.2742 - accuracy: 0.3046\n",
      "Epoch 2/40\n",
      "300/300 [==============================] - 21s 69ms/step - loss: 1.3854 - accuracy: 0.4483\n",
      "Epoch 3/40\n",
      "300/300 [==============================] - 20s 67ms/step - loss: 1.2618 - accuracy: 0.4815\n",
      "Epoch 4/40\n",
      "300/300 [==============================] - 20s 68ms/step - loss: 1.1708 - accuracy: 0.5172\n",
      "Epoch 5/40\n",
      "300/300 [==============================] - 21s 69ms/step - loss: 1.1168 - accuracy: 0.5473\n",
      "Epoch 6/40\n",
      "300/300 [==============================] - 21s 68ms/step - loss: 1.0778 - accuracy: 0.5541\n",
      "Epoch 7/40\n",
      "300/300 [==============================] - 21s 71ms/step - loss: 1.0053 - accuracy: 0.5929\n",
      "Epoch 8/40\n",
      "300/300 [==============================] - 22s 73ms/step - loss: 0.9856 - accuracy: 0.6028\n",
      "Epoch 9/40\n",
      "300/300 [==============================] - 21s 69ms/step - loss: 0.9099 - accuracy: 0.6271\n",
      "Epoch 10/40\n",
      "300/300 [==============================] - 20s 68ms/step - loss: 0.8855 - accuracy: 0.6346\n",
      "Epoch 11/40\n",
      "300/300 [==============================] - 20s 67ms/step - loss: 0.8543 - accuracy: 0.6478\n",
      "Epoch 12/40\n",
      "300/300 [==============================] - 21s 71ms/step - loss: 0.7995 - accuracy: 0.6757\n",
      "Epoch 13/40\n",
      "300/300 [==============================] - 22s 73ms/step - loss: 0.7817 - accuracy: 0.6793\n",
      "Epoch 14/40\n",
      "300/300 [==============================] - 22s 74ms/step - loss: 0.7606 - accuracy: 0.6929\n",
      "Epoch 15/40\n",
      "300/300 [==============================] - 22s 73ms/step - loss: 0.7354 - accuracy: 0.7109\n",
      "Epoch 16/40\n",
      "300/300 [==============================] - 21s 70ms/step - loss: 0.6669 - accuracy: 0.7205\n",
      "Epoch 17/40\n",
      "300/300 [==============================] - 21s 71ms/step - loss: 0.6725 - accuracy: 0.7294\n",
      "Epoch 18/40\n",
      "300/300 [==============================] - 21s 70ms/step - loss: 0.6197 - accuracy: 0.7586\n",
      "Epoch 19/40\n",
      "300/300 [==============================] - 22s 73ms/step - loss: 0.5975 - accuracy: 0.7645\n",
      "Epoch 20/40\n",
      "300/300 [==============================] - 21s 71ms/step - loss: 0.5490 - accuracy: 0.7803\n",
      "Epoch 21/40\n",
      "300/300 [==============================] - 21s 70ms/step - loss: 0.5442 - accuracy: 0.7803\n",
      "Epoch 22/40\n",
      "300/300 [==============================] - 21s 70ms/step - loss: 0.5087 - accuracy: 0.7984\n",
      "Epoch 23/40\n",
      "300/300 [==============================] - 21s 71ms/step - loss: 0.4843 - accuracy: 0.8037\n",
      "Epoch 24/40\n",
      "300/300 [==============================] - 21s 72ms/step - loss: 0.4897 - accuracy: 0.8160\n",
      "Epoch 25/40\n",
      "300/300 [==============================] - 21s 70ms/step - loss: 0.4609 - accuracy: 0.8260\n",
      "Epoch 26/40\n",
      "300/300 [==============================] - 20s 68ms/step - loss: 0.4234 - accuracy: 0.8364\n",
      "Epoch 27/40\n",
      "300/300 [==============================] - 21s 70ms/step - loss: 0.4265 - accuracy: 0.8388\n",
      "Epoch 28/40\n",
      "300/300 [==============================] - 21s 71ms/step - loss: 0.3886 - accuracy: 0.8535\n",
      "Epoch 29/40\n",
      "300/300 [==============================] - 21s 71ms/step - loss: 0.3566 - accuracy: 0.8681\n",
      "Epoch 30/40\n",
      "300/300 [==============================] - 22s 72ms/step - loss: 0.3672 - accuracy: 0.8675\n",
      "Epoch 31/40\n",
      "300/300 [==============================] - 22s 72ms/step - loss: 0.3448 - accuracy: 0.8723\n",
      "Epoch 32/40\n",
      "300/300 [==============================] - 21s 71ms/step - loss: 0.3320 - accuracy: 0.8761\n",
      "Epoch 33/40\n",
      "300/300 [==============================] - 21s 71ms/step - loss: 0.3438 - accuracy: 0.8752\n",
      "Epoch 34/40\n",
      "300/300 [==============================] - 22s 72ms/step - loss: 0.3155 - accuracy: 0.8832\n",
      "Epoch 35/40\n",
      "300/300 [==============================] - 21s 70ms/step - loss: 0.3116 - accuracy: 0.8831\n",
      "Epoch 36/40\n",
      "300/300 [==============================] - 21s 72ms/step - loss: 0.2869 - accuracy: 0.8933\n",
      "Epoch 37/40\n",
      "300/300 [==============================] - 21s 68ms/step - loss: 0.2869 - accuracy: 0.8908\n",
      "Epoch 38/40\n",
      "300/300 [==============================] - 21s 68ms/step - loss: 0.2607 - accuracy: 0.9048\n",
      "Epoch 39/40\n",
      "300/300 [==============================] - 21s 71ms/step - loss: 0.2976 - accuracy: 0.8884\n",
      "Epoch 40/40\n",
      "300/300 [==============================] - 21s 69ms/step - loss: 0.2911 - accuracy: 0.8962\n",
      "model accuracy: 0.8960999846458435\n",
      "Query no. 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imuzumdar/opt/miniconda3/envs/fashion_mnist/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "325/325 [==============================] - 22s 66ms/step - loss: 2.2181 - accuracy: 0.3111\n",
      "Epoch 2/40\n",
      "325/325 [==============================] - 22s 69ms/step - loss: 1.3659 - accuracy: 0.4443\n",
      "Epoch 3/40\n",
      "325/325 [==============================] - 23s 70ms/step - loss: 1.2623 - accuracy: 0.4830\n",
      "Epoch 4/40\n",
      "325/325 [==============================] - 25s 77ms/step - loss: 1.1726 - accuracy: 0.5156\n",
      "Epoch 5/40\n",
      "325/325 [==============================] - 23s 71ms/step - loss: 1.1153 - accuracy: 0.5427\n",
      "Epoch 6/40\n",
      "325/325 [==============================] - 23s 70ms/step - loss: 1.0412 - accuracy: 0.5756\n",
      "Epoch 7/40\n",
      "325/325 [==============================] - 23s 70ms/step - loss: 1.0417 - accuracy: 0.5751\n",
      "Epoch 8/40\n",
      "325/325 [==============================] - 22s 67ms/step - loss: 0.9756 - accuracy: 0.5901\n",
      "Epoch 9/40\n",
      "325/325 [==============================] - 22s 68ms/step - loss: 0.9234 - accuracy: 0.6221\n",
      "Epoch 10/40\n",
      "325/325 [==============================] - 22s 68ms/step - loss: 0.9117 - accuracy: 0.6335\n",
      "Epoch 11/40\n",
      "325/325 [==============================] - 22s 67ms/step - loss: 0.8726 - accuracy: 0.6440\n",
      "Epoch 12/40\n",
      "325/325 [==============================] - 22s 67ms/step - loss: 0.8191 - accuracy: 0.6656\n",
      "Epoch 13/40\n",
      "325/325 [==============================] - 22s 68ms/step - loss: 0.8027 - accuracy: 0.6650\n",
      "Epoch 14/40\n",
      "325/325 [==============================] - 23s 70ms/step - loss: 0.7529 - accuracy: 0.6935\n",
      "Epoch 15/40\n",
      "325/325 [==============================] - 22s 68ms/step - loss: 0.7329 - accuracy: 0.7020\n",
      "Epoch 16/40\n",
      "325/325 [==============================] - 23s 70ms/step - loss: 0.7138 - accuracy: 0.7095\n",
      "Epoch 17/40\n",
      "325/325 [==============================] - 23s 71ms/step - loss: 0.6745 - accuracy: 0.7249\n",
      "Epoch 18/40\n",
      "325/325 [==============================] - 22s 69ms/step - loss: 0.6560 - accuracy: 0.7401\n",
      "Epoch 19/40\n",
      "325/325 [==============================] - 22s 68ms/step - loss: 0.6005 - accuracy: 0.7613\n",
      "Epoch 20/40\n",
      "325/325 [==============================] - 22s 69ms/step - loss: 0.6114 - accuracy: 0.7598\n",
      "Epoch 21/40\n",
      "325/325 [==============================] - 23s 70ms/step - loss: 0.5359 - accuracy: 0.7860\n",
      "Epoch 22/40\n",
      "325/325 [==============================] - 22s 69ms/step - loss: 0.5378 - accuracy: 0.7891\n",
      "Epoch 23/40\n",
      "325/325 [==============================] - 23s 71ms/step - loss: 0.5256 - accuracy: 0.7855\n",
      "Epoch 24/40\n",
      "325/325 [==============================] - 23s 70ms/step - loss: 0.5019 - accuracy: 0.8069\n",
      "Epoch 25/40\n",
      "325/325 [==============================] - 22s 69ms/step - loss: 0.4828 - accuracy: 0.8094\n",
      "Epoch 26/40\n",
      "325/325 [==============================] - 23s 69ms/step - loss: 0.4732 - accuracy: 0.8223\n",
      "Epoch 27/40\n",
      "325/325 [==============================] - 23s 70ms/step - loss: 0.4448 - accuracy: 0.8333\n",
      "Epoch 28/40\n",
      "325/325 [==============================] - 23s 70ms/step - loss: 0.4110 - accuracy: 0.8404\n",
      "Epoch 29/40\n",
      "325/325 [==============================] - 23s 69ms/step - loss: 0.4075 - accuracy: 0.8464\n",
      "Epoch 30/40\n",
      "325/325 [==============================] - 23s 69ms/step - loss: 0.3944 - accuracy: 0.8520\n",
      "Epoch 31/40\n",
      "325/325 [==============================] - 22s 69ms/step - loss: 0.3733 - accuracy: 0.8578\n",
      "Epoch 32/40\n",
      "325/325 [==============================] - 22s 68ms/step - loss: 0.3676 - accuracy: 0.8641\n",
      "Epoch 33/40\n",
      "325/325 [==============================] - 22s 69ms/step - loss: 0.3477 - accuracy: 0.8669\n",
      "Epoch 34/40\n",
      "325/325 [==============================] - 22s 69ms/step - loss: 0.3678 - accuracy: 0.8688\n",
      "Epoch 35/40\n",
      "325/325 [==============================] - 22s 69ms/step - loss: 0.3450 - accuracy: 0.8730\n",
      "Epoch 36/40\n",
      "325/325 [==============================] - 22s 69ms/step - loss: 0.3278 - accuracy: 0.8752\n",
      "Epoch 37/40\n",
      "325/325 [==============================] - 23s 69ms/step - loss: 0.3120 - accuracy: 0.8843\n",
      "Epoch 38/40\n",
      "325/325 [==============================] - 23s 70ms/step - loss: 0.3059 - accuracy: 0.8848\n",
      "Epoch 39/40\n",
      "325/325 [==============================] - 23s 69ms/step - loss: 0.2782 - accuracy: 0.9000\n",
      "Epoch 40/40\n",
      "325/325 [==============================] - 23s 69ms/step - loss: 0.3014 - accuracy: 0.8897\n",
      "model accuracy: 0.8626000285148621\n"
     ]
    }
   ],
   "source": [
    "# 3 more times\n",
    "for idx in range(n_queries, n_queries + 3):\n",
    "    print(f'Query no. {(idx + 1)}')\n",
    "    query_idx, query_instance = learner.query(X_pool, n_instances=400, verbose=0)\n",
    "    X_gen, y_gen = generate_new_samples(X_pool[query_idx], y_pool[query_idx], num_samples=1)\n",
    "    learner.teach(\n",
    "        X=np.concatenate([X_pool[query_idx], X_gen], axis=0),\n",
    "        y=np.concatenate([y_pool[query_idx], y_gen], axis=0), \n",
    "        verbose=1,\n",
    "        epochs=epochs,\n",
    "    )\n",
    "    \n",
    "    # remove queried instance from pool\n",
    "    X_pool = np.delete(X_pool, query_idx, axis=0)\n",
    "    y_pool = np.delete(y_pool, query_idx, axis=0)\n",
    "    \n",
    "    # evaluate performance\n",
    "    model_accuracy = learner.score(X_test, y_test, verbose=0)\n",
    "    accuracy_arr.append(model_accuracy)\n",
    "    print(f\"model accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad5295f",
   "metadata": {},
   "source": [
    "At this point, we've shown our model 5,200 real samples, or 8.667% of the train dataset, and we've surpassed the performance of our baseline!\n",
    "\n",
    "We also have that the test accuracy has increased on almost every iteration of querying (the notable exception being the last iteration). So, for the msot part, our queries are helping the model classify examples of unseen data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37508410",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/imuzumdar/opt/miniconda3/envs/fashion_mnist/lib/python3.9/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "350/350 [==============================] - 25s 70ms/step - loss: 2.2005 - accuracy: 0.3122\n",
      "Epoch 2/40\n",
      "350/350 [==============================] - 24s 70ms/step - loss: 1.3550 - accuracy: 0.4488\n",
      "Epoch 3/40\n",
      "350/350 [==============================] - 24s 70ms/step - loss: 1.2721 - accuracy: 0.4840\n",
      "Epoch 4/40\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 1.1984 - accuracy: 0.5134\n",
      "Epoch 5/40\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 1.1004 - accuracy: 0.5412\n",
      "Epoch 6/40\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 1.0681 - accuracy: 0.5465\n",
      "Epoch 7/40\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 1.0190 - accuracy: 0.5733\n",
      "Epoch 8/40\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 0.9869 - accuracy: 0.5825\n",
      "Epoch 9/40\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 0.9516 - accuracy: 0.5982\n",
      "Epoch 10/40\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 0.9037 - accuracy: 0.6191\n",
      "Epoch 11/40\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 0.8743 - accuracy: 0.6332\n",
      "Epoch 12/40\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 0.8497 - accuracy: 0.6521\n",
      "Epoch 13/40\n",
      "350/350 [==============================] - 25s 72ms/step - loss: 0.8043 - accuracy: 0.6699\n",
      "Epoch 14/40\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 0.7848 - accuracy: 0.6813\n",
      "Epoch 15/40\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 0.7496 - accuracy: 0.6861\n",
      "Epoch 16/40\n",
      "350/350 [==============================] - 25s 72ms/step - loss: 0.7150 - accuracy: 0.7056\n",
      "Epoch 17/40\n",
      "350/350 [==============================] - 25s 72ms/step - loss: 0.6905 - accuracy: 0.7216\n",
      "Epoch 18/40\n",
      "350/350 [==============================] - 25s 72ms/step - loss: 0.6516 - accuracy: 0.7273\n",
      "Epoch 19/40\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 0.6361 - accuracy: 0.7413\n",
      "Epoch 20/40\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 0.6069 - accuracy: 0.7491\n",
      "Epoch 21/40\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 0.5784 - accuracy: 0.7717\n",
      "Epoch 22/40\n",
      "350/350 [==============================] - 25s 72ms/step - loss: 0.5766 - accuracy: 0.7731\n",
      "Epoch 23/40\n",
      "350/350 [==============================] - 25s 70ms/step - loss: 0.5350 - accuracy: 0.7870\n",
      "Epoch 24/40\n",
      "350/350 [==============================] - 25s 70ms/step - loss: 0.5219 - accuracy: 0.7940\n",
      "Epoch 25/40\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 0.4858 - accuracy: 0.8110\n",
      "Epoch 26/40\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 0.4425 - accuracy: 0.8249\n",
      "Epoch 27/40\n",
      "350/350 [==============================] - 25s 70ms/step - loss: 0.4427 - accuracy: 0.8354\n",
      "Epoch 28/40\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 0.4242 - accuracy: 0.8369\n",
      "Epoch 29/40\n",
      "350/350 [==============================] - 25s 70ms/step - loss: 0.4177 - accuracy: 0.8438\n",
      "Epoch 30/40\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 0.4136 - accuracy: 0.8453\n",
      "Epoch 31/40\n",
      "350/350 [==============================] - 25s 71ms/step - loss: 0.3772 - accuracy: 0.8524\n",
      "Epoch 32/40\n",
      "350/350 [==============================] - 25s 73ms/step - loss: 0.3506 - accuracy: 0.8676\n",
      "Epoch 33/40\n",
      "350/350 [==============================] - 25s 72ms/step - loss: 0.3722 - accuracy: 0.8580\n",
      "Epoch 34/40\n",
      "350/350 [==============================] - 25s 72ms/step - loss: 0.3634 - accuracy: 0.8649\n",
      "Epoch 35/40\n",
      "350/350 [==============================] - 26s 73ms/step - loss: 0.3311 - accuracy: 0.8761\n",
      "Epoch 36/40\n",
      "350/350 [==============================] - 24s 67ms/step - loss: 0.3525 - accuracy: 0.8678\n",
      "Epoch 37/40\n",
      "350/350 [==============================] - 24s 69ms/step - loss: 0.2868 - accuracy: 0.8904\n",
      "Epoch 38/40\n",
      "350/350 [==============================] - 24s 68ms/step - loss: 0.3185 - accuracy: 0.8857\n",
      "Epoch 39/40\n",
      "350/350 [==============================] - 24s 69ms/step - loss: 0.3066 - accuracy: 0.8858\n",
      "Epoch 40/40\n",
      "350/350 [==============================] - 24s 69ms/step - loss: 0.2926 - accuracy: 0.8974\n",
      "model accuracy: 0.9006999731063843\n"
     ]
    }
   ],
   "source": [
    "# one more iteration *fingers crossed*\n",
    "query_idx, query_instance = learner.query(X_pool, n_instances=400, verbose=0)\n",
    "X_gen, y_gen = generate_new_samples(X_pool[query_idx], y_pool[query_idx], num_samples=1)\n",
    "learner.teach(\n",
    "    X=np.concatenate([X_pool[query_idx], X_gen], axis=0),\n",
    "    y=np.concatenate([y_pool[query_idx], y_gen], axis=0), \n",
    "#         X=X_pool[query_idx],\n",
    "#         y=y_pool[query_idx],\n",
    "    verbose=1,\n",
    "    epochs=epochs,\n",
    ")\n",
    "\n",
    "# remove queried instance from pool\n",
    "X_pool = np.delete(X_pool, query_idx, axis=0)\n",
    "y_pool = np.delete(y_pool, query_idx, axis=0)\n",
    "\n",
    "# evaluate performance\n",
    "model_accuracy = learner.score(X_test, y_test, verbose=0)\n",
    "accuracy_arr.append(model_accuracy)\n",
    "print(f\"model accuracy: {model_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7be15d2",
   "metadata": {},
   "source": [
    "We hit 90% accuracy! Let's see how much data we used in total."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7e9798a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total samples trained on Active Learner: 11200\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of total samples trained on Active Learner: {len(learner.X_training)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f5532a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Accuracy on Test Set: 0.9006999731063843\n"
     ]
    }
   ],
   "source": [
    "print(f\"Max Accuracy on Test Set: {max(accuracy_arr)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4fd80d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total samples trained at point of Maximum Accuracy: 11200\n",
      "Number of augmented samples trained at point of Maximum Accuracy: 5600\n",
      "Number of real samples trained at point of Maximum Accuracy: 5600\n",
      "Percentage of train data used at point of Maximum Accuracy: 0.09333333333333334\n"
     ]
    }
   ],
   "source": [
    "max_idx = accuracy_arr.index(max(accuracy_arr))\n",
    "num_samples_max_accuracy = n_instances_per_class * 10 + (max_idx + 1) * 400\n",
    "\n",
    "print(f\"Number of total samples trained at point of Maximum Accuracy: {num_samples_max_accuracy * 2}\")\n",
    "print(f\"Number of augmented samples trained at point of Maximum Accuracy: {num_samples_max_accuracy}\")\n",
    "print(f\"Number of real samples trained at point of Maximum Accuracy: {num_samples_max_accuracy}\")\n",
    "print(f\"Percentage of train data used at point of Maximum Accuracy: {num_samples_max_accuracy/X_train.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801287ba",
   "metadata": {},
   "source": [
    "Using active learning and data augmentation, we were able to hit our target accuracy (barely, but still) using only 5,600 queried observations from the labels database. In the end, we only used 9.33% of our train data, which is around half the data we used in our baseline experiment. And, with some finer-grained model tuning, I think it's possible we could hit our accuracy target with even fewer observations. But given the time constraints of this problem, that is outside the scope of this analysis. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
